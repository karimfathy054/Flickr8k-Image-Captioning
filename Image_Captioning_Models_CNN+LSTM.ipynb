{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1111676,
          "sourceType": "datasetVersion",
          "datasetId": 623289
        },
        {
          "sourceId": 8430641,
          "sourceType": "datasetVersion",
          "datasetId": 5020648
        },
        {
          "sourceId": 8466082,
          "sourceType": "datasetVersion",
          "datasetId": 5047414
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Image Captioning Models CNN+LSTM",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h1 align=\"center\">**Name**</h1>|<h1 align=\"center\">**ID**</h1>|\n",
        "|---|---|\n",
        "|<h4 align=\"center\">**Abd Allah Mohamed Abd Allah Mohamed Taman**</h4>|<h4 align=\"center\">**20010906**</h4>|\n",
        "|<h4 align=\"center\">**Karim Fathy Abd Alaziz Mohamed Mostafa**</h4>|<h4 align=\"center\">**20011116**</h4>|\n",
        "|<h4 align=\"center\">**Mahmoud Ali Ahmed Ali**</h4>|<h4 align=\"center\">**20011811**</h4>|:"
      ],
      "metadata": {
        "id": "aXJ3Ccu4QKVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Important modules imports**\n",
        "\n",
        "*   **<font color = \"magenta\" >OS</font>**: used for handling treating with files.\n",
        "*   **<font color = \"magenta\" >tqaddum</font>**: provides a visual indication of loop progress.\n",
        "*   **<font color = \"magenta\" >numpy</font>**: provides mathematical functions useful for treating with vectors and matrices.\n",
        "*   **<font color = \"magenta\" >img_to_array</font>**: convert image to 2d array\n",
        "*   **<font color = \"magenta\" >load_img</font>**: loading the image given the path which lies on.\n",
        "* **<font color = \"magenta\" >Tokenizer</font>**: this is used to convert each text into a sequence of integers.\n",
        "* **<font color = \"magenta\" >pad_sequence</font>**: used to make all sequences in a list have the same length by padding to the maximum sequence length.\n",
        "* **<font color = \"magenta\">Sequential</font>**: used to create sequential models.\n",
        "* **<font color = \"magenta\" >ResNet50</font>**: it is a deep convolutional neural network used for image classification tasks.\n",
        "* **<font color = \"magenta\" >preprocess_input</font>**: preprocesses input images to be compatible with the ResNet50 model.\n",
        "* **<font color = \"magenta\" >layers</font>**: contains classes and functions for defining different layers in a neural network.\n",
        "* **<font color = \"magenta\" >optimizers</font>**: contains classes and functions for defining optimization algorithms to train neural network models."
      ],
      "metadata": {
        "id": "k8xzJT8sQKVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.applications.resnet import ResNet50,preprocess_input\n",
        "from keras.callbacks import EarlyStopping,History,ModelCheckpoint,Callback\n",
        "from keras.layers import *\n",
        "from keras.models import Model,Sequential\n",
        "from keras.preprocessing.image import img_to_array,load_img\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical,plot_model\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.translate.bleu_score import corpus_bleu,sentence_bleu,SmoothingFunction\n",
        "from keras.saving import load_model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:37.681703Z",
          "iopub.execute_input": "2024-05-20T21:23:37.682586Z",
          "iopub.status.idle": "2024-05-20T21:23:37.689398Z",
          "shell.execute_reply.started": "2024-05-20T21:23:37.682552Z",
          "shell.execute_reply": "2024-05-20T21:23:37.68848Z"
        },
        "trusted": true,
        "id": "tXRHZfCSQKVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = \"/kaggle/working/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:37.911527Z",
          "iopub.execute_input": "2024-05-20T21:23:37.911852Z",
          "iopub.status.idle": "2024-05-20T21:23:37.915949Z",
          "shell.execute_reply.started": "2024-05-20T21:23:37.911826Z",
          "shell.execute_reply": "2024-05-20T21:23:37.915104Z"
        },
        "trusted": true,
        "id": "Pq-OEFCzQKVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using ResNet to extract image features from all the dataset images\n"
      ],
      "metadata": {
        "id": "pVQT1DBAQKVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet50()\n",
        "resnet = Model(resnet.input,resnet.layers[-2].output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:38:31.240377Z",
          "iopub.execute_input": "2024-05-20T22:38:31.241199Z",
          "iopub.status.idle": "2024-05-20T22:38:33.719537Z",
          "shell.execute_reply.started": "2024-05-20T22:38:31.241169Z",
          "shell.execute_reply": "2024-05-20T22:38:33.7187Z"
        },
        "trusted": true,
        "id": "VMpPfa_lQKVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_features = {}\n",
        "def img_preprocessing():\n",
        "    for image in tqdm(dataset[\"image\"].unique().tolist())\n",
        "        img = load_img(img_path,target_size=(224,224))\n",
        "        img = img_to_array(img)\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        img = preprocess_input(img)\n",
        "        feature = resnet.predict(img,verbose=0)\n",
        "        feature = feature.reshape(2048,)\n",
        "        img_features[image] = feature"
      ],
      "metadata": {
        "id": "eg5sdReJQKVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saveing image features for further use"
      ],
      "metadata": {
        "id": "P-5bhZAwQKVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_features = pickle.load(open(\"/kaggle/input/my-files/features (1).pkl\",\"rb\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:41.828726Z",
          "iopub.execute_input": "2024-05-20T21:23:41.8294Z",
          "iopub.status.idle": "2024-05-20T21:23:43.365767Z",
          "shell.execute_reply.started": "2024-05-20T21:23:41.829361Z",
          "shell.execute_reply": "2024-05-20T21:23:43.364724Z"
        },
        "trusted": true,
        "id": "hLDs17D1QKVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring dataset"
      ],
      "metadata": {
        "id": "1C-ztkYxQKVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:43.36762Z",
          "iopub.execute_input": "2024-05-20T21:23:43.367975Z",
          "iopub.status.idle": "2024-05-20T21:23:43.466626Z",
          "shell.execute_reply.started": "2024-05-20T21:23:43.367942Z",
          "shell.execute_reply": "2024-05-20T21:23:43.465588Z"
        },
        "trusted": true,
        "id": "bxwF-QqGQKVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:43.468664Z",
          "iopub.execute_input": "2024-05-20T21:23:43.469032Z",
          "iopub.status.idle": "2024-05-20T21:23:43.492747Z",
          "shell.execute_reply.started": "2024-05-20T21:23:43.468998Z",
          "shell.execute_reply": "2024-05-20T21:23:43.4917Z"
        },
        "trusted": true,
        "id": "I18Z6-reQKVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(dataset):\n",
        "    dataset[\"caption\"] = dataset[\"caption\"].apply(lambda x:x.lower())\n",
        "    dataset[\"caption\"] = dataset[\"caption\"].apply(lambda x:x.replace(\"[^A-Za-z]\",\"\"))\n",
        "    dataset[\"caption\"] = dataset[\"caption\"].apply(lambda x:x.replace(\"\\s+\",\" \"))\n",
        "    dataset[\"caption\"] = dataset[\"caption\"].apply(lambda x:\" \".join(word for word in x.split() if len(word)>1))\n",
        "    dataset[\"caption\"] = \"ssttaarrtt \" + dataset[\"caption\"] + \" eenndd\"\n",
        "    return dataset\n",
        "text_preprocess(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:43.495025Z",
          "iopub.execute_input": "2024-05-20T21:23:43.495433Z",
          "iopub.status.idle": "2024-05-20T21:23:43.735221Z",
          "shell.execute_reply.started": "2024-05-20T21:23:43.495392Z",
          "shell.execute_reply": "2024-05-20T21:23:43.73422Z"
        },
        "trusted": true,
        "id": "yVi1YuAqQKVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spliting dataset to train,validate and test sets"
      ],
      "metadata": {
        "id": "oW9By8eDQKVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = dataset[\"image\"].unique().tolist()\n",
        "images_number = len(images)\n",
        "\n",
        "images_training_set = images[:6000]\n",
        "images_validation_set = images[6000:7000]\n",
        "images_test_set = images[7000:8000]\n",
        "\n",
        "training_set = dataset[dataset[\"image\"].isin(images_training_set)]\n",
        "validation_set = dataset[dataset[\"image\"].isin(images_validation_set)]\n",
        "test_set = dataset[dataset[\"image\"].isin(images_test_set)]\n",
        "\n",
        "training_set.reset_index(drop=True,inplace=True)\n",
        "validation_set.reset_index(drop=True,inplace=True)\n",
        "test_set.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:46.752172Z",
          "iopub.execute_input": "2024-05-20T21:23:46.752873Z",
          "iopub.status.idle": "2024-05-20T21:23:46.78169Z",
          "shell.execute_reply.started": "2024-05-20T21:23:46.75284Z",
          "shell.execute_reply": "2024-05-20T21:23:46.780633Z"
        },
        "trusted": true,
        "id": "GhbuhTxRQKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Vocab from dataset captions"
      ],
      "metadata": {
        "id": "A_kM83I4QKVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(training_set[\"caption\"].tolist())\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_sentence_len = max([len(s.split()) for s in training_set[\"caption\"].tolist()])\n",
        "\n",
        "print(f\"\"\"\n",
        "vocab size = {vocab_size}\n",
        "max sentence length = {max_sentence_len}\n",
        "images number = {images_number}\n",
        "\"\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:48.69962Z",
          "iopub.execute_input": "2024-05-20T21:23:48.699966Z",
          "iopub.status.idle": "2024-05-20T21:23:49.293949Z",
          "shell.execute_reply.started": "2024-05-20T21:23:48.69994Z",
          "shell.execute_reply": "2024-05-20T21:23:49.292978Z"
        },
        "trusted": true,
        "id": "VIWSdHT-QKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mapping 5 captions to image"
      ],
      "metadata": {
        "id": "Y5CgilroQKVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ref={}\n",
        "for image in tqdm(training_set[\"image\"].unique().tolist()):\n",
        "    references = training_set.loc[training_set[\"image\"]==image]\n",
        "    references = references[\"caption\"]\n",
        "    references = [x.split() for x in references]\n",
        "    train_ref[image] = references\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:23:51.155336Z",
          "iopub.execute_input": "2024-05-20T21:23:51.156024Z",
          "iopub.status.idle": "2024-05-20T21:24:26.541485Z",
          "shell.execute_reply.started": "2024-05-20T21:23:51.155995Z",
          "shell.execute_reply": "2024-05-20T21:24:26.540528Z"
        },
        "trusted": true,
        "id": "Kc-Hc2StQKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_ref={}\n",
        "for image in tqdm(validation_set[\"image\"].unique().tolist()):\n",
        "    references = validation_set.loc[validation_set[\"image\"]==image]\n",
        "    references = references[\"caption\"]\n",
        "    references = [x.split() for x in references]\n",
        "    validate_ref[image] = references\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:24:26.543084Z",
          "iopub.execute_input": "2024-05-20T21:24:26.543396Z",
          "iopub.status.idle": "2024-05-20T21:24:28.070361Z",
          "shell.execute_reply.started": "2024-05-20T21:24:26.54337Z",
          "shell.execute_reply": "2024-05-20T21:24:28.069131Z"
        },
        "trusted": true,
        "id": "y_q8wxjUQKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ref={}\n",
        "for image in tqdm(test_set[\"image\"].unique().tolist()):\n",
        "    references = test_set.loc[test_set[\"image\"]==image]\n",
        "    references = references[\"caption\"]\n",
        "    references = [x.split() for x in references]\n",
        "    test_ref[image] = references\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:24:28.071803Z",
          "iopub.execute_input": "2024-05-20T21:24:28.072175Z",
          "iopub.status.idle": "2024-05-20T21:24:29.546137Z",
          "shell.execute_reply.started": "2024-05-20T21:24:28.072142Z",
          "shell.execute_reply": "2024-05-20T21:24:29.545134Z"
        },
        "trusted": true,
        "id": "lLT9AqhiQKVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spliting extracted features to different sets"
      ],
      "metadata": {
        "id": "pC_VtwB7QKVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat = list(img_features.values())\n",
        "training_features =  all_feat[:6000]\n",
        "validation_features =  all_feat[6000:7000]\n",
        "test_features =  all_feat[7000:8000]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:24:29.548625Z",
          "iopub.execute_input": "2024-05-20T21:24:29.549216Z",
          "iopub.status.idle": "2024-05-20T21:24:29.555151Z",
          "shell.execute_reply.started": "2024-05-20T21:24:29.54918Z",
          "shell.execute_reply": "2024-05-20T21:24:29.5541Z"
        },
        "trusted": true,
        "id": "hetYOm9yQKVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generator\n",
        "* used for feeding training_data on batches to the Model during training to save memory"
      ],
      "metadata": {
        "id": "hUPQTrNRQKVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(dataset,img_features,tokenizer,vocab_size,max_sentence_length,batch_size):\n",
        "    image_features,learn_seq,word_seq=[],[],[]\n",
        "    size=0\n",
        "    while True:\n",
        "        for image,caption in zip(dataset[\"image\"].tolist(),dataset[\"caption\"].tolist()):\n",
        "            size+=1\n",
        "            sequence = tokenizer.texts_to_sequences([caption])[0]\n",
        "            for i in range(len(sequence)):\n",
        "                in_seq,out_seq = sequence[:i],sequence[i]\n",
        "                in_seq = pad_sequences([in_seq],maxlen=max_sentence_length)[0]\n",
        "                out_seq = to_categorical([out_seq],num_classes=vocab_size)[0]\n",
        "                learn_seq.append(in_seq)\n",
        "                word_seq.append(out_seq)\n",
        "                image_features.append(img_features[image])\n",
        "            if(size==batch_size):\n",
        "                image_features=np.array(image_features)\n",
        "                learn_seq = np.array(learn_seq)\n",
        "                word_seq = np.array(word_seq)\n",
        "                yield (image_features,learn_seq),word_seq\n",
        "                image_features,learn_seq,word_seq=[],[],[]\n",
        "                size=0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:24:47.862786Z",
          "iopub.execute_input": "2024-05-20T21:24:47.863642Z",
          "iopub.status.idle": "2024-05-20T21:24:47.873057Z",
          "shell.execute_reply.started": "2024-05-20T21:24:47.8636Z",
          "shell.execute_reply": "2024-05-20T21:24:47.872123Z"
        },
        "trusted": true,
        "id": "_8QemNb9QKVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 (partial_injection model)\n",
        "* feature vector for input image is concatenated to each word vector in the sequence that is being fed to the LSTM layer in order to influence the output of the sequence.\n",
        "* the model consists of an lstm to study the sequence of the words\n",
        "* the output of the that lstm (whole sequence) is concatinated with img vector\n",
        "* the merged vector is fed to another lstm to predict the next word\n",
        "* at last the predected word vector is fed to a Dense layer of the size of the vocab(available classes) with softmax activation function to predict the suitable word\n",
        "\n",
        "\n",
        "![image.png](attachment:a4434833-7a67-4997-bb30-93d29ceaad55.png)"
      ],
      "metadata": {
        "id": "TnPRy4PkQKVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#par_inject model\n",
        "image_input = Input(shape=(2048,))\n",
        "image_embedder = Dense(128,activation='relu')(image_input)\n",
        "encoder_output = RepeatVector(max_sentence_len)(image_embedder)\n",
        "\n",
        "text_input = Input(shape=(max_sentence_len,))\n",
        "text_embedding = Embedding(vocab_size,128)(text_input)\n",
        "sequence_encoder = LSTM(256,return_sequences=True)(text_embedding)\n",
        "sequence_embedder = TimeDistributed(Dense(128))(sequence_encoder)\n",
        "\n",
        "concat = Concatenate()([encoder_output,sequence_embedder])\n",
        "decoder = LSTM(128,return_sequences=True)(concat)\n",
        "decoder2 = LSTM(512)(decoder)\n",
        "output = Dense(vocab_size,activation='softmax')(decoder2)\n",
        "\n",
        "model = Model([image_input,text_input],output,name=\"hamadabta3medium\")\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "plot_model(model,show_shapes=True)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-20T06:03:16.186674Z",
          "iopub.execute_input": "2024-05-20T06:03:16.187312Z",
          "iopub.status.idle": "2024-05-20T06:03:17.441023Z",
          "shell.execute_reply.started": "2024-05-20T06:03:16.187281Z",
          "shell.execute_reply": "2024-05-20T06:03:17.440182Z"
        },
        "trusted": true,
        "id": "zgRPNIENQKVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# implementing a CallBack for calculating BLEU score after each epoch"
      ],
      "metadata": {
        "id": "Hl06IFi6QKVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "class BLEUCallback(Callback):\n",
        "    def __init__(self, tokenizer,img_features,max_sentence_len,training_img,training_references,validation_img,validation_references,test_img,test_references,batch_size):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.img_features = img_features\n",
        "        self.max_sentence_len = max_sentence_len\n",
        "        self.training_img = training_img\n",
        "        self.training_references = training_references\n",
        "\n",
        "        self.validation_img = validation_img\n",
        "        self.validation_references = validation_references\n",
        "\n",
        "        self.test_img = test_img\n",
        "        self.test_references = test_references\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        validation_predictions = self.get_caption(self.validation_img)\n",
        "        validation_bleu_4 = 0.0\n",
        "        smoothie = SmoothingFunction().method4\n",
        "        for prediction,reference in zip(validation_predictions,self.validation_references):\n",
        "            validation_bleu_4 += (corpus_bleu([reference],[prediction.split()],smoothing_function=smoothie))\n",
        "            validation_bleu_4 = validation_bleu_4/2.0\n",
        "\n",
        "        logs[\"val_bleu_4\"]=validation_bleu_4\n",
        "\n",
        "    def get_caption(self,images):\n",
        "        predictions = []\n",
        "        for i in range(0,len(images),self.batch_size):\n",
        "            batch = images[i:i+self.batch_size]\n",
        "            sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "            for i in range(self.max_sentence_len):\n",
        "                sequence = self.tokenizer.texts_to_sequences(sentences)\n",
        "                sequence = pad_sequences(sequence,maxlen=self.max_sentence_len)\n",
        "                yhat = self.model.predict((np.array(batch),sequence),verbose=0)\n",
        "                yhat = np.argmax(yhat,axis=-1)\n",
        "                word = [self.tokenizer.index_word[pred] for pred in yhat]\n",
        "                sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "        predictions.extend(sentences)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:25:31.954304Z",
          "iopub.execute_input": "2024-05-20T21:25:31.954661Z",
          "iopub.status.idle": "2024-05-20T21:25:31.969294Z",
          "shell.execute_reply.started": "2024-05-20T21:25:31.954635Z",
          "shell.execute_reply": "2024-05-20T21:25:31.968497Z"
        },
        "trusted": true,
        "id": "9aO0ojC4QKVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Stoped after 28 epochs out of 50 to avoid overfitting on training data\n",
        "the used value of weights for the model is the values that correspond to the epoch with the lowest validation loss"
      ],
      "metadata": {
        "id": "0uHQ7HjhQKVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(WORKING_DIR+\"par_injectModel.keras\",save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=10,restore_best_weights=True)\n",
        "bleusda = BLEUCallback(tokenizer,img_features,max_sentence_len,training_features,train_ref.values(),validation_features,validate_ref.values(),test_features,test_ref.values(),100)\n",
        "\n",
        "epochs = 40\n",
        "batch_size = 100\n",
        "train_step = len(training_set)//batch_size\n",
        "val_step = len(validation_set)//batch_size\n",
        "train_gen = data_generator(training_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "val_gen = data_generator(validation_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "\n",
        "history = model.fit(train_gen,validation_data=val_gen,epochs=epochs,steps_per_epoch=train_step,validation_steps=val_step,verbose=1,callbacks=[checkpoint,early_stop,bleusda])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:03:39.104456Z",
          "iopub.execute_input": "2024-05-20T06:03:39.105229Z",
          "iopub.status.idle": "2024-05-20T06:51:20.8747Z",
          "shell.execute_reply.started": "2024-05-20T06:03:39.105196Z",
          "shell.execute_reply": "2024-05-20T06:51:20.873861Z"
        },
        "trusted": true,
        "id": "kiq1a-zxQKVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(history.history,open(\"par_injectModel\",\"wb\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T02:49:11.14918Z",
          "iopub.execute_input": "2024-05-20T02:49:11.149895Z",
          "iopub.status.idle": "2024-05-20T02:49:11.154603Z",
          "shell.execute_reply.started": "2024-05-20T02:49:11.149864Z",
          "shell.execute_reply": "2024-05-20T02:49:11.153663Z"
        },
        "trusted": true,
        "id": "jZNkd-DRQKVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pickle.load(open(\"par_injectModel\",\"rb\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T03:26:34.723364Z",
          "iopub.execute_input": "2024-05-20T03:26:34.724072Z",
          "iopub.status.idle": "2024-05-20T03:26:34.729108Z",
          "shell.execute_reply.started": "2024-05-20T03:26:34.724038Z",
          "shell.execute_reply": "2024-05-20T03:26:34.727845Z"
        },
        "trusted": true,
        "id": "yqBV5G-9QKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history.history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:51:21.107365Z",
          "iopub.execute_input": "2024-05-20T06:51:21.10765Z",
          "iopub.status.idle": "2024-05-20T06:51:21.111755Z",
          "shell.execute_reply.started": "2024-05-20T06:51:21.107625Z",
          "shell.execute_reply": "2024-05-20T06:51:21.110837Z"
        },
        "trusted": true,
        "id": "olLOHDyjQKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting loss\n",
        "plt.plot(range(1,len(history[\"loss\"])+1),history[\"loss\"],color='g',label=\"training_loss\")\n",
        "plt.plot(range(1,len(history[\"val_loss\"])+1),history[\"val_loss\"],color='orange',label=\"validation_loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:51:21.113753Z",
          "iopub.execute_input": "2024-05-20T06:51:21.114052Z",
          "iopub.status.idle": "2024-05-20T06:51:21.337125Z",
          "shell.execute_reply.started": "2024-05-20T06:51:21.114028Z",
          "shell.execute_reply": "2024-05-20T06:51:21.336236Z"
        },
        "trusted": true,
        "id": "1tKop9X3QKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting accuracy\n",
        "plt.plot(range(1,len(history[\"accuracy\"])+1),history[\"accuracy\"],color='g',label=\"training_accuracy\")\n",
        "plt.plot(range(1,len(history[\"val_accuracy\"])+1),history[\"val_accuracy\"],color='orange',label=\"validation_accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:51:21.338088Z",
          "iopub.execute_input": "2024-05-20T06:51:21.338323Z",
          "iopub.status.idle": "2024-05-20T06:51:21.539434Z",
          "shell.execute_reply.started": "2024-05-20T06:51:21.338302Z",
          "shell.execute_reply": "2024-05-20T06:51:21.538638Z"
        },
        "trusted": true,
        "id": "_FZR7zzOQKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting BLEU-4 for validation\n",
        "plt.plot(range(1,len(history[\"val_bleu_4\"])+1),history[\"val_bleu_4\"],color='r',label=\"validation_bleu_score\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"BLEU-4\")\n",
        "plt.title(\"BLEU-4 value for validation set\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:51:21.540682Z",
          "iopub.execute_input": "2024-05-20T06:51:21.541027Z",
          "iopub.status.idle": "2024-05-20T06:51:21.730154Z",
          "shell.execute_reply.started": "2024-05-20T06:51:21.540975Z",
          "shell.execute_reply": "2024-05-20T06:51:21.729298Z"
        },
        "trusted": true,
        "id": "Ycj7aC30QKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(WORKING_DIR+\"/par_inject_model.keras\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T03:00:48.224446Z",
          "iopub.execute_input": "2024-05-20T03:00:48.225124Z",
          "iopub.status.idle": "2024-05-20T03:00:48.519843Z",
          "shell.execute_reply.started": "2024-05-20T03:00:48.225092Z",
          "shell.execute_reply": "2024-05-20T03:00:48.518787Z"
        },
        "trusted": true,
        "id": "fv1HG7ThQKVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Model(with Add layer)\n",
        "this model does not take image features into account during training the lstm layer as the RNN train only on the sequences of text and their order while extracted image features are only added to the output of the RNN to influence the probability of the chosen next word by the lstm, by adding the values of image features vector to the output  of the RNN and using a Dense layer with \"relu\" activation function to decode that new merged vector to another Dense layer of size equal to vocab size of our captions that utilizes \"softmax\" activation function to get the word class corresponding to the highest probability\n",
        "\n",
        "![image.png](attachment:41f6e0d1-2332-478c-bb32-286193681f8b.png)"
      ],
      "metadata": {
        "id": "QWgqV9BcQKVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#merging Model(with add)\n",
        "img_input = Input(shape=(2048,))\n",
        "dropout = Dropout(0.5)(img_input)\n",
        "img_embedding = Dense(256,activation='relu')(dropout)\n",
        "\n",
        "text_input = Input(shape=(max_sentence_len,))\n",
        "text_embedding = Embedding(vocab_size,256)(text_input)\n",
        "lstm = LSTM(256)(text_embedding)\n",
        "dropout = Dropout(0.5)(lstm)\n",
        "\n",
        "merging = Add()([img_embedding,dropout])\n",
        "\n",
        "decoder = Dense(256,activation='relu')(merging)\n",
        "output = Dense(vocab_size,activation='softmax')(decoder)\n",
        "\n",
        "model2 = Model([img_input,text_input],output,name=\"Merging_Model_add\")\n",
        "model2.compile(loss = \"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "plot_model(model2,show_shapes=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:25:09.991572Z",
          "iopub.execute_input": "2024-05-20T21:25:09.992031Z",
          "iopub.status.idle": "2024-05-20T21:25:11.854339Z",
          "shell.execute_reply.started": "2024-05-20T21:25:09.991992Z",
          "shell.execute_reply": "2024-05-20T21:25:11.85341Z"
        },
        "trusted": true,
        "id": "m81wopjtQKVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Stoped after 15 epochs out of 50 to avoid overfitting on training data\n",
        "the used value of weights for the model is the values that correspond to the epoch with the lowest validation loss"
      ],
      "metadata": {
        "id": "acv-MKWqQKVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(WORKING_DIR+\"merging_model.keras\",save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=10,restore_best_weights=True)\n",
        "bleusCall= BLEUCallback(tokenizer,img_features,max_sentence_len,training_features,train_ref.values(),validation_features,validate_ref.values(),test_features,test_ref.values(),100)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "train_step = len(training_set)//batch_size\n",
        "val_step = len(validation_set)//batch_size\n",
        "train_gen = data_generator(training_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "val_gen = data_generator(validation_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "\n",
        "history2 = model2.fit(train_gen,validation_data=val_gen,epochs=epochs,steps_per_epoch=train_step,validation_steps=val_step,verbose=1,callbacks=[checkpoint,early_stop,bleusCall])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:25:48.844648Z",
          "iopub.execute_input": "2024-05-20T21:25:48.845008Z",
          "iopub.status.idle": "2024-05-20T21:46:21.516081Z",
          "shell.execute_reply.started": "2024-05-20T21:25:48.84498Z",
          "shell.execute_reply": "2024-05-20T21:46:21.515083Z"
        },
        "trusted": true,
        "id": "-6V2U2j-QKVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyModel_2 = history2.history\n",
        "plt.plot(range(1,len(historyModel_2[\"loss\"])+1),historyModel_2[\"loss\"],color='g',label=\"train_loss\")\n",
        "plt.plot(range(1,len(historyModel_2[\"val_loss\"])+1),historyModel_2[\"val_loss\"],color='r',label=\"val_loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:46:21.518166Z",
          "iopub.execute_input": "2024-05-20T21:46:21.518807Z",
          "iopub.status.idle": "2024-05-20T21:46:21.845438Z",
          "shell.execute_reply.started": "2024-05-20T21:46:21.518772Z",
          "shell.execute_reply": "2024-05-20T21:46:21.844321Z"
        },
        "trusted": true,
        "id": "tSbg1zn7QKVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,len(historyModel_2[\"accuracy\"])+1),historyModel_2[\"accuracy\"],color='g',label=\"train_accuracy\")\n",
        "plt.plot(range(1,len(historyModel_2[\"val_accuracy\"])+1),historyModel_2[\"val_accuracy\"],color='r',label=\"val_accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:46:21.846956Z",
          "iopub.execute_input": "2024-05-20T21:46:21.847361Z",
          "iopub.status.idle": "2024-05-20T21:46:22.119225Z",
          "shell.execute_reply.started": "2024-05-20T21:46:21.847325Z",
          "shell.execute_reply": "2024-05-20T21:46:22.118298Z"
        },
        "trusted": true,
        "id": "HD_O1Bp0QKVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,len(historyModel_2[\"val_bleu_4\"])+1),historyModel_2[\"val_bleu_4\"],color='g',label=\"val_bleu_4\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.title(\"BLEU-4 score for validations set\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:46:22.121958Z",
          "iopub.execute_input": "2024-05-20T21:46:22.12259Z",
          "iopub.status.idle": "2024-05-20T21:46:22.387639Z",
          "shell.execute_reply.started": "2024-05-20T21:46:22.122545Z",
          "shell.execute_reply": "2024-05-20T21:46:22.386762Z"
        },
        "trusted": true,
        "id": "hugydClsQKVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(historyModel_2,open(WORKING_DIR+\"model_merging_history.pkl\",\"wb\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T03:56:21.513323Z",
          "iopub.execute_input": "2024-05-20T03:56:21.513686Z",
          "iopub.status.idle": "2024-05-20T03:56:21.51885Z",
          "shell.execute_reply.started": "2024-05-20T03:56:21.513658Z",
          "shell.execute_reply": "2024-05-20T03:56:21.517949Z"
        },
        "trusted": true,
        "id": "okOoJumJQKVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(WORKING_DIR+\"merging_model_add.keras\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:00:41.616588Z",
          "iopub.execute_input": "2024-05-20T04:00:41.617011Z",
          "iopub.status.idle": "2024-05-20T04:00:41.837424Z",
          "shell.execute_reply.started": "2024-05-20T04:00:41.616981Z",
          "shell.execute_reply": "2024-05-20T04:00:41.834746Z"
        },
        "trusted": true,
        "id": "xI-0rS-YQKVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Model (Concatenate merging)\n",
        "similar to the previous Merge model the model doesn't use the image features vector to influence the inner sequences of the RNN rather, it uses the vector to affect the value of the decoded outcome of the RNN layer\n",
        "\n",
        "that model utilizes a Concatenate Layer rather than an Add layer in order to preserve the outcome of the RNN without change but uses the Dense layer to decode the larger concatenated vector"
      ],
      "metadata": {
        "id": "Eeu009zWQKVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder model\n",
        "# image feature layers\n",
        "inputs1 = Input(shape=(2048,), name=\"image\")\n",
        "fe2 = Dense(256, activation='relu')(inputs1)\n",
        "\n",
        "# sequence feature layers\n",
        "inputs2 = Input(shape=(max_sentence_len,), name=\"text\")\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=False)(inputs2)\n",
        "se3 = LSTM(256)(se1)\n",
        "\n",
        "concat = Concatenate()([fe2, se3])\n",
        "\n",
        "x = Dense (vocab_size)(concat)\n",
        "x = Dropout(0.3)(x)\n",
        "out = Activation('softmax')(x)\n",
        "\n",
        "model3 = Model(inputs=[inputs1, inputs2], outputs=out,name=\"merging_model_concat\")\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# plot the model\n",
        "plot_model(model3, show_shapes=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:02:07.93542Z",
          "iopub.execute_input": "2024-05-20T04:02:07.936287Z",
          "iopub.status.idle": "2024-05-20T04:02:08.232892Z",
          "shell.execute_reply.started": "2024-05-20T04:02:07.936253Z",
          "shell.execute_reply": "2024-05-20T04:02:08.23196Z"
        },
        "trusted": true,
        "id": "9OKOQu1ZQKVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Stoped after 19 epochs out of 50 to avoid overfitting on training data\n",
        "the used value of weights for the model is the values that correspond to the epoch with the lowest validation loss"
      ],
      "metadata": {
        "id": "ShxJ2al0QKVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(WORKING_DIR+\"merging_model_concat_chackpoint.keras\",save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=10,restore_best_weights=True)\n",
        "bleusCall= BLEUCallback(tokenizer,img_features,max_sentence_len,training_features,train_ref.values(),validation_features,validate_ref.values(),test_features,test_ref.values(),100)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "train_step = len(training_set)//batch_size\n",
        "val_step = len(validation_set)//batch_size\n",
        "train_gen = data_generator(training_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "val_gen = data_generator(validation_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "\n",
        "history3 = model3.fit(train_gen,validation_data=val_gen,epochs=epochs,steps_per_epoch=train_step,validation_steps=val_step,verbose=1,callbacks=[checkpoint,early_stop,bleusCall])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:02:12.566565Z",
          "iopub.execute_input": "2024-05-20T04:02:12.567271Z",
          "iopub.status.idle": "2024-05-20T04:28:29.00227Z",
          "shell.execute_reply.started": "2024-05-20T04:02:12.567241Z",
          "shell.execute_reply": "2024-05-20T04:28:29.001175Z"
        },
        "trusted": true,
        "id": "9KD2U6NMQKVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyModel_3 = history3.history\n",
        "plt.plot(range(1,len(historyModel_3[\"loss\"])+1),historyModel_3[\"loss\"],color='g',label=\"train_loss\")\n",
        "plt.plot(range(1,len(historyModel_3[\"val_loss\"])+1),historyModel_3[\"val_loss\"],color='r',label=\"val_loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:30:21.053898Z",
          "iopub.execute_input": "2024-05-20T04:30:21.054701Z",
          "iopub.status.idle": "2024-05-20T04:30:21.32888Z",
          "shell.execute_reply.started": "2024-05-20T04:30:21.054671Z",
          "shell.execute_reply": "2024-05-20T04:30:21.327948Z"
        },
        "trusted": true,
        "id": "ReA0DGZdQKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyModel_3 = history3.history\n",
        "plt.plot(range(1,len(historyModel_3[\"accuracy\"])+1),historyModel_3[\"accuracy\"],color='g',label=\"train_accuracy\")\n",
        "plt.plot(range(1,len(historyModel_3[\"val_accuracy\"])+1),historyModel_3[\"val_accuracy\"],color='r',label=\"val_accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:31:46.041251Z",
          "iopub.execute_input": "2024-05-20T04:31:46.041612Z",
          "iopub.status.idle": "2024-05-20T04:31:46.313307Z",
          "shell.execute_reply.started": "2024-05-20T04:31:46.041586Z",
          "shell.execute_reply": "2024-05-20T04:31:46.312116Z"
        },
        "trusted": true,
        "id": "UQJoscTNQKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyModel_3 = history3.history\n",
        "plt.plot(range(1,len(historyModel_3[\"val_bleu_4\"])+1),historyModel_3[\"val_bleu_4\"],color='g',label=\"val_bleu_4\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"BLUE-4\")\n",
        "plt.title(\"BLUE-4 score for validation set\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:33:20.467131Z",
          "iopub.execute_input": "2024-05-20T04:33:20.467899Z",
          "iopub.status.idle": "2024-05-20T04:33:20.789037Z",
          "shell.execute_reply.started": "2024-05-20T04:33:20.467855Z",
          "shell.execute_reply": "2024-05-20T04:33:20.787977Z"
        },
        "trusted": true,
        "id": "4QF6lz2fQKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_caption(model,image,img_features,tokenizer,max_sentence_len):\n",
        "    sentence = \"ssttaarrtt\"\n",
        "    img_feature = np.array([img_features[image]])\n",
        "    for i in range(max_sentence_len):\n",
        "        sequence = tokenizer.texts_to_sequences([sentence])\n",
        "        sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "        yhat = model.predict((img_feature,sequence),verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word[yhat]\n",
        "        sentence +=\" \"+word\n",
        "        if(word == \"eenndd\"):\n",
        "            break\n",
        "    return sentence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T05:02:38.41393Z",
          "iopub.execute_input": "2024-05-20T05:02:38.414272Z",
          "iopub.status.idle": "2024-05-20T05:02:38.421473Z",
          "shell.execute_reply.started": "2024-05-20T05:02:38.414245Z",
          "shell.execute_reply": "2024-05-20T05:02:38.420422Z"
        },
        "trusted": true,
        "id": "ME1pqDUFQKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = tf.keras.models.load_model(\"/kaggle/working/par_inject_model.keras\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:57:21.387551Z",
          "iopub.execute_input": "2024-05-20T04:57:21.388342Z",
          "iopub.status.idle": "2024-05-20T04:57:22.421165Z",
          "shell.execute_reply.started": "2024-05-20T04:57:21.388307Z",
          "shell.execute_reply": "2024-05-20T04:57:22.420217Z"
        },
        "trusted": true,
        "id": "I67ZPqItQKVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_caption(first_model,training_set[\"image\"][0],img_features,tokenizer,max_sentence_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T05:02:43.030411Z",
          "iopub.execute_input": "2024-05-20T05:02:43.030765Z",
          "iopub.status.idle": "2024-05-20T05:02:44.142835Z",
          "shell.execute_reply.started": "2024-05-20T05:02:43.030738Z",
          "shell.execute_reply": "2024-05-20T05:02:44.141909Z"
        },
        "trusted": true,
        "id": "8MZXbI1_QKVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproting test_set on first model\n",
        "predictions = []\n",
        "for i in tqdm(range(0,len(test_features),100)):\n",
        "    batch = test_features[i:i+100]\n",
        "    sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "    for i in range(max_sentence_len):\n",
        "        sequence = tokenizer.texts_to_sequences(sentences)\n",
        "        sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "        yhat = first_model.predict((np.array(batch),sequence),verbose=0)\n",
        "        yhat = np.argmax(yhat,axis=-1)\n",
        "        word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "        sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "    predictions.extend(sentences)\n",
        "\n",
        "bleu_1 = 0.0\n",
        "bleu_2 = 0.0\n",
        "bleu_3 = 0.0\n",
        "bleu_4 = 0.0\n",
        "smoothi1 = SmoothingFunction().method1\n",
        "smoothi2 = SmoothingFunction().method2\n",
        "smoothi3 = SmoothingFunction().method3\n",
        "smoothi4 = SmoothingFunction().method4\n",
        "\n",
        "\n",
        "for predection,reference in zip(predictions,list(test_ref.values())):\n",
        "    bleu_1 += corpus_bleu([reference],[predection.split()],weights=(1.0,0.0,0.0,0.0),smoothing_function=smoothi1)\n",
        "    bleu_2 += corpus_bleu([reference],[predection.split()],weights=(0.5,0.5,0.0,0.0),smoothing_function=smoothi2)\n",
        "    bleu_3 += corpus_bleu([reference],[predection.split()],weights=(0.3,0.3,0.3,0.0),smoothing_function=smoothi3)\n",
        "    bleu_4 += corpus_bleu([reference],[predection.split()],weights=(0.25,0.25,0.25,0.25),smoothing_function=smoothi4)\n",
        "    bleu_1 = bleu_1/2.0\n",
        "    bleu_2 = bleu_2/2.0\n",
        "    bleu_3 = bleu_3/2.0\n",
        "    bleu_4 = bleu_4/2.0\n",
        "\n",
        "print(f\"test set cumulative BLEU-1: {bleu_1}\")\n",
        "print(f\"test set cumulative BLEU-2: {bleu_2}\")\n",
        "print(f\"test set cumulative BLEU-3: {bleu_3}\")\n",
        "print(f\"test set cumulative BLEU-4: {bleu_4}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T05:03:39.000043Z",
          "iopub.execute_input": "2024-05-20T05:03:39.000702Z",
          "iopub.status.idle": "2024-05-20T05:04:13.938591Z",
          "shell.execute_reply.started": "2024-05-20T05:03:39.000657Z",
          "shell.execute_reply": "2024-05-20T05:04:13.937695Z"
        },
        "trusted": true,
        "id": "1_q4CrX_QKVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproting test_set on 3rd model only\n",
        "predictions = []\n",
        "for i in tqdm(range(0,len(test_features),100)):\n",
        "    batch = test_features[i:i+100]\n",
        "    sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "    for i in range(max_sentence_len):\n",
        "        sequence = tokenizer.texts_to_sequences(sentences)\n",
        "        sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "        yhat = model3.predict((np.array(batch),sequence),verbose=0)\n",
        "        yhat = np.argmax(yhat,axis=-1)\n",
        "        word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "        sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "    predictions.extend(sentences)\n",
        "\n",
        "bleu_1 = 0.0\n",
        "bleu_2 = 0.0\n",
        "bleu_3 = 0.0\n",
        "bleu_4 = 0.0\n",
        "smoothi1 = SmoothingFunction().method1\n",
        "smoothi2 = SmoothingFunction().method2\n",
        "smoothi3 = SmoothingFunction().method3\n",
        "smoothi4 = SmoothingFunction().method4\n",
        "\n",
        "\n",
        "for predection,reference in zip(predictions,list(test_ref.values())):\n",
        "    bleu_1 += corpus_bleu([reference],[predection.split()],weights=(1.0,0.0,0.0,0.0),smoothing_function=smoothi1)\n",
        "    bleu_2 += corpus_bleu([reference],[predection.split()],weights=(0.5,0.5,0.0,0.0),smoothing_function=smoothi2)\n",
        "    bleu_3 += corpus_bleu([reference],[predection.split()],weights=(0.3,0.3,0.3,0.0),smoothing_function=smoothi3)\n",
        "    bleu_4 += corpus_bleu([reference],[predection.split()],weights=(0.25,0.25,0.25,0.25),smoothing_function=smoothi4)\n",
        "    bleu_1 = bleu_1/2.0\n",
        "    bleu_2 = bleu_2/2.0\n",
        "    bleu_3 = bleu_3/2.0\n",
        "    bleu_4 = bleu_4/2.0\n",
        "\n",
        "print(f\"test set cumulative BLEU-1: {bleu_1}\")\n",
        "print(f\"test set cumulative BLEU-2: {bleu_2}\")\n",
        "print(f\"test set cumulative BLEU-3: {bleu_3}\")\n",
        "print(f\"test set cumulative BLEU-4: {bleu_4}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T04:54:23.351825Z",
          "iopub.execute_input": "2024-05-20T04:54:23.352656Z",
          "iopub.status.idle": "2024-05-20T04:54:52.233829Z",
          "shell.execute_reply.started": "2024-05-20T04:54:23.352608Z",
          "shell.execute_reply": "2024-05-20T04:54:52.232881Z"
        },
        "trusted": true,
        "id": "kfuPuHsOQKVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#examples\n",
        "example_predictions = []\n",
        "batch = test_features[:20]\n",
        "sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "for i in range(max_sentence_len):\n",
        "    sequence = tokenizer.texts_to_sequences(sentences)\n",
        "    sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "    yhat = model3.predict((np.array(batch),sequence),verbose=0)\n",
        "    yhat = np.argmax(yhat,axis=-1)\n",
        "    word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "    sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "example_predictions.extend(sentences)"
      ],
      "metadata": {
        "trusted": true,
        "id": "89FPfD5SQKVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,image in enumerate(test_set[\"image\"].unique().tolist()):\n",
        "    img = load_img(\"/kaggle/input/flickr8k/Images\"+image)\n",
        "    print(\"actual captions:\")\n",
        "    captions=test_set.loc[test_set[\"image\"]==image]\n",
        "    for caption in  captions[\"caption\"].tolist():\n",
        "        print(\"caption\")\n",
        "    print(\"predicted caption:\")\n",
        "    print(example_predictions[i])\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "Tv4SK_33QKVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modified inject model\n"
      ],
      "metadata": {
        "id": "kfblh_NCQKVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_input = Input(shape=(2048,))\n",
        "dropout = Dropout(0.5)(img_input)\n",
        "img_embedding = Dense(256,activation='relu')(dropout)\n",
        "encoder_output = RepeatVector(max_sentence_len)(img_embedding)\n",
        "\n",
        "text_input = Input(shape=(max_sentence_len,))\n",
        "text_embedding = Embedding(vocab_size,256)(text_input)\n",
        "dropout = Dropout(0.5)(text_embedding)\n",
        "\n",
        "merge = Concatenate()([encoder_output,dropout])\n",
        "\n",
        "lstm = LSTM(256)(merge)\n",
        "\n",
        "decoder = Dense(256,activation='relu')(lstm)\n",
        "output = Dense(vocab_size,activation=\"softmax\")(decoder)\n",
        "\n",
        "modelSpecial = Model([img_input,text_input],output)\n",
        "modelSpecial.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "plot_model(modelSpecial,show_shapes=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:48:07.111389Z",
          "iopub.execute_input": "2024-05-20T21:48:07.111836Z",
          "iopub.status.idle": "2024-05-20T21:48:07.537522Z",
          "shell.execute_reply.started": "2024-05-20T21:48:07.111804Z",
          "shell.execute_reply": "2024-05-20T21:48:07.536463Z"
        },
        "trusted": true,
        "id": "mWJQanXtQKVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(WORKING_DIR+\"injecting_model_withdropouts.keras\",save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=5,restore_best_weights=True)\n",
        "bleusCall= BLEUCallback(tokenizer,img_features,max_sentence_len,training_features,train_ref.values(),validation_features,validate_ref.values(),test_features,test_ref.values(),100)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "train_step = len(training_set)//batch_size\n",
        "val_step = len(validation_set)//batch_size\n",
        "train_gen = data_generator(training_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "val_gen = data_generator(validation_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "\n",
        "historyLast = modelSpecial.fit(train_gen,validation_data=val_gen,epochs=epochs,steps_per_epoch=train_step,validation_steps=val_step,verbose=1,callbacks=[checkpoint,early_stop,bleusCall])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T21:48:48.610493Z",
          "iopub.execute_input": "2024-05-20T21:48:48.610863Z",
          "iopub.status.idle": "2024-05-20T22:04:07.98515Z",
          "shell.execute_reply.started": "2024-05-20T21:48:48.610835Z",
          "shell.execute_reply": "2024-05-20T22:04:07.984304Z"
        },
        "trusted": true,
        "id": "GPpX0zf2QKVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = historyLast.history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:04:16.900667Z",
          "iopub.execute_input": "2024-05-20T22:04:16.901476Z",
          "iopub.status.idle": "2024-05-20T22:04:16.90739Z",
          "shell.execute_reply.started": "2024-05-20T22:04:16.901436Z",
          "shell.execute_reply": "2024-05-20T22:04:16.906284Z"
        },
        "trusted": true,
        "id": "hHgxXSSTQKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,len(h[\"loss\"])+1),h[\"loss\"],color='g',label=\"train_loss\")\n",
        "plt.plot(range(1,len(h[\"val_loss\"])+1),h[\"val_loss\"],color='r',label=\"val_loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:04:17.121409Z",
          "iopub.execute_input": "2024-05-20T22:04:17.121995Z",
          "iopub.status.idle": "2024-05-20T22:04:17.390563Z",
          "shell.execute_reply.started": "2024-05-20T22:04:17.121965Z",
          "shell.execute_reply": "2024-05-20T22:04:17.389356Z"
        },
        "trusted": true,
        "id": "xkRrV421QKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,len(h[\"accuracy\"])+1),h[\"accuracy\"],color='g',label=\"train_accuracy\")\n",
        "plt.plot(range(1,len(h[\"val_accuracy\"])+1),h[\"val_accuracy\"],color='r',label=\"val_accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:04:17.440567Z",
          "iopub.execute_input": "2024-05-20T22:04:17.440866Z",
          "iopub.status.idle": "2024-05-20T22:04:17.698675Z",
          "shell.execute_reply.started": "2024-05-20T22:04:17.44084Z",
          "shell.execute_reply": "2024-05-20T22:04:17.697687Z"
        },
        "trusted": true,
        "id": "20Tk1HuCQKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,len(h[\"val_bleu_4\"])+1),h[\"val_bleu_4\"],color='g',label=\"val_bleu_4\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"BLEU-4\")\n",
        "plt.title(\"accumulative BLEU-4 score for validation data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:04:22.923211Z",
          "iopub.execute_input": "2024-05-20T22:04:22.924118Z",
          "iopub.status.idle": "2024-05-20T22:04:23.166051Z",
          "shell.execute_reply.started": "2024-05-20T22:04:22.924086Z",
          "shell.execute_reply": "2024-05-20T22:04:23.165096Z"
        },
        "trusted": true,
        "id": "Y5heKD3cQKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in tqdm(range(0,len(test_features),100)):\n",
        "    batch = test_features[i:i+100]\n",
        "    sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "    for i in range(max_sentence_len):\n",
        "        sequence = tokenizer.texts_to_sequences(sentences)\n",
        "        sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "        yhat = modelSpecial.predict((np.array(batch),sequence),verbose=0)\n",
        "        yhat = np.argmax(yhat,axis=-1)\n",
        "        word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "        sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "    predictions.extend(sentences)\n",
        "\n",
        "bleu_1 = 0.0\n",
        "bleu_2 = 0.0\n",
        "bleu_3 = 0.0\n",
        "bleu_4 = 0.0\n",
        "smoothi1 = SmoothingFunction().method1\n",
        "smoothi2 = SmoothingFunction().method2\n",
        "smoothi3 = SmoothingFunction().method3\n",
        "smoothi4 = SmoothingFunction().method4\n",
        "\n",
        "reference = list(test_ref.values())\n",
        "predection = [x.split() for x in predictions]\n",
        "bleu_1 = corpus_bleu(reference,predection,weights=(1.0,0.0,0.0,0.0),smoothing_function=smoothi1)\n",
        "bleu_2 = corpus_bleu(reference,predection,weights=(0.5,0.5,0.0,0.0),smoothing_function=smoothi2)\n",
        "bleu_3 = corpus_bleu(reference,predection,weights=(0.3,0.3,0.3,0.0),smoothing_function=smoothi3)\n",
        "bleu_4 = corpus_bleu(reference,predection,weights=(0.25,0.25,0.25,0.25),smoothing_function=smoothi4)\n",
        "\n",
        "\n",
        "print(f\"test set cumulative BLEU-1: {bleu_1}\")\n",
        "print(f\"test set cumulative BLEU-2: {bleu_2}\")\n",
        "print(f\"test set cumulative BLEU-3: {bleu_3}\")\n",
        "print(f\"test set cumulative BLEU-4: {bleu_4}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:07:40.738134Z",
          "iopub.execute_input": "2024-05-20T22:07:40.738795Z",
          "iopub.status.idle": "2024-05-20T22:08:08.831776Z",
          "shell.execute_reply.started": "2024-05-20T22:07:40.738763Z",
          "shell.execute_reply": "2024-05-20T22:08:08.830828Z"
        },
        "trusted": true,
        "id": "ONwNQ6lLQKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#examples\n",
        "example_predictions = []\n",
        "batch = test_features[:20]\n",
        "sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "for i in range(max_sentence_len):\n",
        "    sequence = tokenizer.texts_to_sequences(sentences)\n",
        "    sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "    yhat = modelSpecial.predict((np.array(batch),sequence),verbose=0)\n",
        "    yhat = np.argmax(yhat,axis=-1)\n",
        "    word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "    sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "example_predictions.extend(sentences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:09:18.472071Z",
          "iopub.execute_input": "2024-05-20T22:09:18.473031Z",
          "iopub.status.idle": "2024-05-20T22:09:20.672378Z",
          "shell.execute_reply.started": "2024-05-20T22:09:18.472985Z",
          "shell.execute_reply": "2024-05-20T22:09:20.671517Z"
        },
        "trusted": true,
        "id": "D-O-PO1YQKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,image in enumerate(test_set[\"image\"].unique().tolist()[:20]):\n",
        "    img = load_img(\"/kaggle/input/flickr8k/Images/\"+image)\n",
        "    print(\"___________________actual captions___________________\")\n",
        "    captions=test_set.loc[test_set[\"image\"]==image]\n",
        "    for caption in  captions[\"caption\"].tolist():\n",
        "        print(caption)\n",
        "    print(\"___________________predicted captions___________________\")\n",
        "    print(example_predictions[i])\n",
        "    print(\"___________________Image___________________\")\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:13:14.24933Z",
          "iopub.execute_input": "2024-05-20T22:13:14.250095Z",
          "iopub.status.idle": "2024-05-20T22:13:20.163198Z",
          "shell.execute_reply.started": "2024-05-20T22:13:14.250061Z",
          "shell.execute_reply": "2024-05-20T22:13:20.162285Z"
        },
        "trusted": true,
        "id": "-Og4mwt9QKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overfitting the model\n",
        "checkpoint = ModelCheckpoint(WORKING_DIR+\"injecting_model_withdropouts.keras\",save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=5,restore_best_weights=True)\n",
        "bleusCall= BLEUCallback(tokenizer,img_features,max_sentence_len,training_features,train_ref.values(),validation_features,validate_ref.values(),test_features,test_ref.values(),100)\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "train_step = len(training_set)//batch_size\n",
        "val_step = len(validation_set)//batch_size\n",
        "train_gen = data_generator(training_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "val_gen = data_generator(validation_set,img_features,tokenizer,vocab_size,max_sentence_len,batch_size)\n",
        "\n",
        "historyLast = modelSpecial.fit(train_gen,validation_data=val_gen,epochs=epochs,steps_per_epoch=train_step,validation_steps=val_step,verbose=1,callbacks=[checkpoint,bleusCall],initial_epoch=7)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:16:10.78095Z",
          "iopub.execute_input": "2024-05-20T22:16:10.78135Z",
          "iopub.status.idle": "2024-05-20T22:34:02.63437Z",
          "shell.execute_reply.started": "2024-05-20T22:16:10.78132Z",
          "shell.execute_reply": "2024-05-20T22:34:02.633291Z"
        },
        "trusted": true,
        "id": "LNMmIKgCQKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for overfitted model\n",
        "\n",
        "predictions = []\n",
        "for i in tqdm(range(0,len(test_features),100)):\n",
        "    batch = test_features[i:i+100]\n",
        "    sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "    for i in range(max_sentence_len):\n",
        "        sequence = tokenizer.texts_to_sequences(sentences)\n",
        "        sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "        yhat = modelSpecial.predict((np.array(batch),sequence),verbose=0)\n",
        "        yhat = np.argmax(yhat,axis=-1)\n",
        "        word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "        sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "    predictions.extend(sentences)\n",
        "\n",
        "bleu_1 = 0.0\n",
        "bleu_2 = 0.0\n",
        "bleu_3 = 0.0\n",
        "bleu_4 = 0.0\n",
        "smoothi1 = SmoothingFunction().method1\n",
        "smoothi2 = SmoothingFunction().method2\n",
        "smoothi3 = SmoothingFunction().method3\n",
        "smoothi4 = SmoothingFunction().method4\n",
        "\n",
        "reference = list(test_ref.values())\n",
        "predection = [x.split() for x in predictions]\n",
        "bleu_1 = corpus_bleu(reference,predection,weights=(1.0,0.0,0.0,0.0),smoothing_function=smoothi1)\n",
        "bleu_2 = corpus_bleu(reference,predection,weights=(0.5,0.5,0.0,0.0),smoothing_function=smoothi2)\n",
        "bleu_3 = corpus_bleu(reference,predection,weights=(0.3,0.3,0.3,0.0),smoothing_function=smoothi3)\n",
        "bleu_4 = corpus_bleu(reference,predection,weights=(0.25,0.25,0.25,0.25),smoothing_function=smoothi4)\n",
        "\n",
        "\n",
        "print(f\"test set cumulative BLEU-1: {bleu_1}\")\n",
        "print(f\"test set cumulative BLEU-2: {bleu_2}\")\n",
        "print(f\"test set cumulative BLEU-3: {bleu_3}\")\n",
        "print(f\"test set cumulative BLEU-4: {bleu_4}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:35:59.40342Z",
          "iopub.execute_input": "2024-05-20T22:35:59.403794Z",
          "iopub.status.idle": "2024-05-20T22:36:26.545795Z",
          "shell.execute_reply.started": "2024-05-20T22:35:59.403768Z",
          "shell.execute_reply": "2024-05-20T22:36:26.544827Z"
        },
        "trusted": true,
        "id": "dsy7vpDSQKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#using eternal examples\n",
        "external_features = []\n",
        "for image in tqdm(os.listdir(\"/kaggle/input/amsfbashb\")):\n",
        "    img = load_img(os.path.join(\"/kaggle/input/amsfbashb\",image),target_size=(224,224))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    feature = resnet.predict(img,verbose=0)\n",
        "    feature = feature.reshape(2048,)\n",
        "    external_features.append(feature)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:39:55.676043Z",
          "iopub.execute_input": "2024-05-20T22:39:55.676389Z",
          "iopub.status.idle": "2024-05-20T22:39:56.145274Z",
          "shell.execute_reply.started": "2024-05-20T22:39:55.676363Z",
          "shell.execute_reply": "2024-05-20T22:39:56.14419Z"
        },
        "trusted": true,
        "id": "EL5O31K0QKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_predictions = []\n",
        "batch = external_features\n",
        "sentences = [\"ssttaarrtt\"]*len(batch)\n",
        "for i in range(max_sentence_len):\n",
        "    sequence = tokenizer.texts_to_sequences(sentences)\n",
        "    sequence = pad_sequences(sequence,maxlen=max_sentence_len)\n",
        "    yhat = modelSpecial.predict((np.array(batch),sequence),verbose=0)\n",
        "    yhat = np.argmax(yhat,axis=-1)\n",
        "    word = [tokenizer.index_word[pred] for pred in yhat]\n",
        "    sentences =[sentences[k]+\" \"+word[k] if word[k] is not None and word[k] !=\"eenndd\" else sentences[k] for k in range(len(sentences))]\n",
        "external_predictions.extend(sentences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:43:08.444217Z",
          "iopub.execute_input": "2024-05-20T22:43:08.444606Z",
          "iopub.status.idle": "2024-05-20T22:43:10.493424Z",
          "shell.execute_reply.started": "2024-05-20T22:43:08.444576Z",
          "shell.execute_reply": "2024-05-20T22:43:10.492582Z"
        },
        "trusted": true,
        "id": "Wx94tWGBQKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image,caption in zip(os.listdir(\"/kaggle/input/amsfbashb\"),external_predictions) :\n",
        "    print(f\"Caption == {caption[1:]}\")\n",
        "    img = load_img(os.path.join(\"/kaggle/input/amsfbashb\",image))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T22:44:48.964986Z",
          "iopub.execute_input": "2024-05-20T22:44:48.965461Z",
          "iopub.status.idle": "2024-05-20T22:44:50.857928Z",
          "shell.execute_reply.started": "2024-05-20T22:44:48.96543Z",
          "shell.execute_reply": "2024-05-20T22:44:50.856962Z"
        },
        "trusted": true,
        "id": "Jpev8D7rQKVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}